# ğŸŒ¦ï¸ City Weather Analytics Service :

## ğŸ“Œ Project Overview
This project is a Data Processing & Analytics Service built with **Python**, **FastAPI**, and **Pandas**. It performs a full ETL (Extract, Transform, Load) pipeline that:

1.  **Ingests** real-world city data from a CSV file.
2.  **Fetches** real-time weather data via the **OpenWeatherMap API**.
3.  **Cleans** and normalizes the data (handling nulls, duplicates, and outliers).
4.  **Transforms** the data by adding derived insights (Temperature Categories, Population Buckets).
5.  **Exposes** the processed data via a high-performance **REST API** with pagination and filtering.

## ğŸš€ Key Features
*   **Automated ETL Pipeline**: Runs automatically on application startup.
*   **Robust Data Cleaning**: Handles missing coordinates, type casting errors, and duplicates.
*   **Real-time Integration**: Merges static CSV data with live API weather data.
*   **Modern REST API**: Built with FastAPI, including Swagger UI documentation.
*   **Advanced Features**: Pagination, Filtering (`min_population`, `temp_category`), and Health Checks.
*   **Containerization**: Fully Docker/Podman compatible.
*   **Structured Logging**: Professional logging configuration for debugging and monitoring.

---

## ğŸ“‚ Project Structure

```text
WEATHER_SERVER/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ worldcities.csv      # Source dataset
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ merged_data.csv      # Generated by the pipeline
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Environment configuration
â”‚   â”œâ”€â”€ logger.py                # Centralized logging setup
â”‚   â”œâ”€â”€ api_client.py            # OpenWeatherMap API logic
â”‚   â”œâ”€â”€ data_loader.py           # CSV ingestion
â”‚   â”œâ”€â”€ data_cleaner.py          # Cleaning logic (Pandas)
â”‚   â”œâ”€â”€ transformer.py           # Merging & Feature Engineering
â”‚   â””â”€â”€ app.py                   # FastAPI Application
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â”œâ”€â”€ test_cleaner.py
â”‚   â””â”€â”€ test_transformer.py
â”‚
â”œâ”€â”€ .env                         # Credentials
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile                   # Container configuration
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md

ğŸ› ï¸ Setup & Installation

1. Prerequisites


Python 3.9+
Git
An OpenWeatherMap API Key 
(Optional) Podman or Docker


2. Clone the Repository


Bash

git clone <your-repo-url>
cd WEATHER_SERVER

3. Setup Virtual Environment


Bash

# Linux/Mac
python3 -m venv venv
source venv/bin/activate



# Windows
python -m venv venv
.\venv\Scripts\activate


4. Install Dependencies


Bash


pip install -r requirements.txt



5. Configuration (.env)

Create a .env file in the root directory and add your API credentials:



OPENWEATHER_API_KEY=your_real_api_key_here
RAW_DATA_PATH=data/raw/worldcities.csv
PROCESSED_DATA_PATH=data/processed/merged_data.csv
ENV=development



6. Prepare Data

Ensure you have the source CSV file at data/raw/worldcities.csv.

(If you don't have the file, download "World Cities" from SimpleMaps or create a dummy CSV with columns: city, lat, lng, country, population).


ğŸƒâ€â™‚ï¸ How to Run



Option A: Run Locally (Python)


Start the server using Uvicorn (hot-reload enabled):

Bash

uvicorn src.main:app --reload

API URL: http://127.0.0.1:8000

Documentation: http://127.0.0.1:8000/docs





Option B: Run with Podman / Docker

This application is OCI-compliant. You can use Docker or Podman commands interchangeably.

Build the Image:


Bash

podman build -t weather-api .

Run the Container:
(Pass the .env file so the container can access your API Key)

Bash

podman run -d --name weather-app -p 8000:8000 --env-file .env weather-api


Check Logs:


Bash


podman logs -f weather-app




ğŸ“¡ API Endpoints



Method	      Endpoint	           Description	Query Params
GET	             /	Root             endpoint	     N/A
GET	             /health	        Health check	 Returns status & row count
GET	             /cities	        List cities	     page, page_size, temp_category, min_population
GET	            /cities/{name}	   Get single city	   N/A



Example Usage


Get Hot Cities (Temp > 25Â°C) with Population > 5 Million:

http

GET /cities?temp_category=Hot&min_population=5000000


ğŸ§ª Testing


Unit tests are written using pytest to validate data cleaning and transformation logic.

Run tests with:

Bash

pytest tests/

ğŸ“ Design Decisions

FastAPI vs Flask: Chosen FastAPI for automatic Swagger documentation and async capabilities.

Pandas: Used for efficient in-memory data manipulation and vectorization.

Startup Event: The ETL pipeline runs on startup. In a production scenario, this might be moved to a background worker (Celery/Airflow), but for this assignment, running it on startup ensures data availability immediately.

Logging: print statements were avoided in favor of the logging module for better observability in Docker logs.
